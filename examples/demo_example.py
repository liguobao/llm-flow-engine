#!/usr/bin/env python3
"""
LLM Flow Engine æ¼”ç¤ºç¤ºä¾‹
å±•ç¤ºæ–°æ¶æ„çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è‡ªå®šä¹‰æ¨¡å‹é…ç½®
2. DSLå·¥ä½œæµæ‰§è¡Œ
3. å¤šæ¨¡å‹é—®ç­”æ±‡æ€»
"""
import asyncio
import aiohttp
import time
from loguru import logger
from llm_flow_engine import FlowEngine, ModelConfigProvider
import sys
logger.remove()
logger.add(sys.stderr, level="INFO")

async def demo_basic_usage():
    logger.info("LLM Flow Engine æ¼”ç¤º")
    logger.info("=" * 50)
    
    # 1. è‡ªå®šä¹‰æ¨¡å‹é…ç½®
    logger.info("1. è‡ªå®šä¹‰æ¨¡å‹é…ç½®")
    # ollama pull gemma3:1b
    # ollama pull qwen2.5:0.5b
    # ollama pull gemma3:4b
    # ollama pull deepseek-r1:7b
    ollama_host = "http://127.0.0.1:11434"
    custom_models = await load_models_from_ollama(ollama_host)
    logger.info(f"æˆåŠŸåŠ è½½ {len(custom_models)} ä¸ªæ¨¡å‹é…ç½®")
    
    # åˆ›å»ºè‡ªå®šä¹‰é…ç½®æä¾›è€…
    custom_provider = ModelConfigProvider(custom_models)
    engine = FlowEngine(custom_provider)
    
    # æŸ¥çœ‹æ”¯æŒçš„æ¨¡å‹
    models = engine.model_provider.list_supported_models()
    total_models = sum(len(model_list) for model_list in models.values())
    logger.info(f"æ”¯æŒ {total_models} ä¸ªæ¨¡å‹ï¼Œæ¶µç›– {len(models)} ä¸ªå¹³å°")
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹åˆ—è¡¨
    for platform, model_list in models.items():
        if model_list:
            logger.info(f"  {platform}: {', '.join(model_list[:5])}{'...' if len(model_list) > 5 else ''}")

    # 2. ä»æœ¬åœ°æ–‡ä»¶è¯»å–DSLå¹¶æ‰§è¡Œå¤šæ¨¡å‹é—®ç­”æ±‡æ€»
    logger.info("2. æœ¬åœ°Ollamaæ¨¡å‹é—®ç­”æ±‡æ€»æ¼”ç¤º")
    logger.info("é—®é¢˜: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
    logger.info("æ¨¡å‹: gemma3:1b, qwen2.5:0.5b")
    logger.info("æ–¹æ¡ˆ: ä¸¤ä¸ªå°æ¨¡å‹åˆ†åˆ«å›ç­”ï¼Œç„¶åç”¨gemma3:1bè¿›è¡Œæ±‡æ€»åˆ†æ")

    try:
        # è¯»å–æœ¬åœ°DSLæ–‡ä»¶
        logger.info("è¯»å–DSLé…ç½®æ–‡ä»¶...")
        with open('./examples/demo_qa.yaml', 'r', encoding='utf-8') as f:
            dsl_content = f.read()

        logger.info("æˆåŠŸè¯»å–DSLæ–‡ä»¶: demo_qa.yaml")
        logger.info("å¼€å§‹è°ƒç”¨æœ¬åœ°Ollamaæ¨¡å‹...")

        # å‡†å¤‡å·¥ä½œæµè¾“å…¥å‚æ•°
        workflow_input = {
            "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"  # ç”¨æˆ·å®é™…çš„é—®é¢˜
        }
        
        logger.info(f"å·¥ä½œæµè¾“å…¥å‚æ•°: {workflow_input}")
        
        # å±•ç¤ºæ‰§è¡Œè®¡åˆ’
        logger.info("å·¥ä½œæµæ‰§è¡Œè®¡åˆ’:")
        logger.info("  1. text_processing - æ–‡æœ¬é¢„å¤„ç†")
        logger.info("  2. model1_answer - gemma3:1b æ¨¡å‹å›ç­”")
        logger.info("  3. model2_answer - qwen2.5:0.5b æ¨¡å‹å›ç­”") 
        logger.info("  4. deep_analysis - gemma3:1b æ·±åº¦åˆ†ææ±‡æ€»")
        logger.info("  5. workflow_output - ç”Ÿæˆæœ€ç»ˆè¾“å‡º")
        
        start_time = time.time()
        
        # æ‰§è¡Œå¤šæ¨¡å‹é—®ç­”DSL
        logger.info("å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        qa_result = await engine.execute_dsl(dsl_content, inputs={"workflow_input": workflow_input})
        
        execution_time = time.time() - start_time
        logger.info(f"å·¥ä½œæµæ€»æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        
        if qa_result['success']:
            logger.info("å¤šæ¨¡å‹é—®ç­”æ‰§è¡ŒæˆåŠŸ!")
            
            # æ˜¾ç¤ºå·¥ä½œæµå…ƒæ•°æ®
            if 'metadata' in qa_result:
                metadata = qa_result['metadata']
                logger.info(f"å·¥ä½œæµä¿¡æ¯:")
                logger.info(f"   ç‰ˆæœ¬: {metadata.get('version', 'æœªæŒ‡å®š')}")
                logger.info(f"   æè¿°: {metadata.get('description', 'æœªæŒ‡å®š')}")

            # æŒ‰æ‰§è¡Œé¡ºåºæ˜¾ç¤ºæ¯ä¸€æ­¥çš„è¯¦ç»†ç»“æœ
            logger.info(f"è¯¦ç»†æ‰§è¡Œæ­¥éª¤ç»“æœ:")
            
            # 1. æ–‡æœ¬å¤„ç†æ­¥éª¤
            if 'text_processing' in qa_result['results']:
                text_result = qa_result['results']['text_processing']
                logger.info(f"æ­¥éª¤1: æ–‡æœ¬å¤„ç†")
                logger.info(f"   çŠ¶æ€: {'æˆåŠŸ' if text_result.status == 'success' else 'å¤±è´¥'}")
                if text_result.status == 'success':
                    logger.info(f"   è¾“å…¥: {workflow_input['question']}")
                    logger.info(f"   è¾“å‡º: {text_result.output}")
                    logger.info(f"   è€—æ—¶: {text_result.exec_time:.3f}ç§’")
                else:
                    logger.error(f"   é”™è¯¯: {text_result.error}")

            # 2. æ¨¡å‹å›ç­”æ­¥éª¤
            model_answers = []
            step_num = 2
            for name, exec_result in qa_result['results'].items():
                if name.endswith('_answer'):
                    model_name = name.replace('_answer', '').replace('model', 'Model')
                    logger.info(f"æ­¥éª¤{step_num}: {model_name} å›ç­”")
                    logger.info(f"   çŠ¶æ€: {'æˆåŠŸ' if exec_result.status == 'success' else 'å¤±è´¥'}")
                    
                    if exec_result.status == 'success':
                        answer = exec_result.output
                        logger.info(f"   æ¨¡å‹: {exec_result.custom_vars.get('model', 'æœªçŸ¥')}")
                        logger.info(f"   è€—æ—¶: {exec_result.exec_time:.3f}ç§’")
                        logger.info(f"   å›ç­”é•¿åº¦: {len(answer)} å­—ç¬¦")
                        logger.info(f"   å›ç­”å†…å®¹: {answer}")
                        model_answers.append(answer)
                    else:
                        logger.error(f"   é”™è¯¯: {exec_result.error}")
                    step_num += 1

            # 3. æ·±åº¦åˆ†ææ­¥éª¤
            if 'deep_analysis' in qa_result['results']:
                analysis_result = qa_result['results']['deep_analysis']
                logger.info(f"æ­¥éª¤{step_num}: æ·±åº¦åˆ†æ")
                logger.info(f"   çŠ¶æ€: {'æˆåŠŸ' if analysis_result.status == 'success' else 'å¤±è´¥'}")
                
                if analysis_result.status == 'success':
                    logger.info(f"   æ¨¡å‹: {analysis_result.custom_vars.get('model', 'æœªçŸ¥')}")
                    logger.info(f"   è€—æ—¶: {analysis_result.exec_time:.3f}ç§’")
                    logger.info(f"   åˆ†æç»“æœ: {analysis_result.output}")
                else:
                    logger.error(f"   é”™è¯¯: {analysis_result.error}")

            # 4. æœ€ç»ˆè¾“å‡ºç»“æœ
            if 'workflow_output' in qa_result['results']:
                output_result = qa_result['results']['workflow_output']
                logger.info(f"ï¿½ æœ€ç»ˆå·¥ä½œæµè¾“å‡º:")
                logger.info(f"   çŠ¶æ€: {'æˆåŠŸ' if output_result.status == 'success' else 'å¤±è´¥'}")
                
                if output_result.status == 'success' and hasattr(output_result, 'output') and isinstance(output_result.output, dict):
                    output_data = output_result.output
                    logger.info(f"   åŸå§‹é—®é¢˜: {output_data.get('original_question', 'N/A')}")
                    logger.info(f"   å¤„ç†åé—®é¢˜: {output_data.get('processed_question', 'N/A')}")
                    
                    if 'model_answers' in output_data:
                        logger.info(f"   æ¨¡å‹å›ç­”æ±‡æ€»:")
                        for model, answer in output_data['model_answers'].items():
                            logger.info(f"     - {model}: {answer[:100]}{'...' if len(answer) > 100 else ''}")
                    
                    if 'summary' in output_data:
                        logger.info(f"   ç»¼åˆæ€»ç»“: {output_data['summary']}")

            # æ‰§è¡Œç»Ÿè®¡
            total_steps = len(qa_result['results'])
            success_steps = sum(1 for result in qa_result['results'].values() if result.status == 'success')
            total_time = sum(result.exec_time for result in qa_result['results'].values() if hasattr(result, 'exec_time'))
            
            logger.info(f"æ‰§è¡Œç»Ÿè®¡:")
            logger.info(f"   æ€»æ­¥éª¤æ•°: {total_steps}")
            logger.info(f"   æˆåŠŸæ­¥éª¤: {success_steps}")
            logger.info(f"   å¤±è´¥æ­¥éª¤: {total_steps - success_steps}")
            logger.info(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
            logger.info(f"   æˆåŠŸç‡: {(success_steps/total_steps*100):.1f}%")

        else:
            logger.error(f" å¤šæ¨¡å‹é—®ç­”å¤±è´¥: {qa_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            # æ˜¾ç¤ºå¤±è´¥çš„æ­¥éª¤è¯¦æƒ…
            if 'results' in qa_result:
                logger.info(" å¤±è´¥æ­¥éª¤è¯¦æƒ…:")
                for name, result in qa_result['results'].items():
                    if result.status != 'success':
                        logger.error(f"   {name}: {result.error}")
                    else:
                        logger.info(f"   {name}: æ‰§è¡ŒæˆåŠŸ")

    except FileNotFoundError:
        logger.error(" æœªæ‰¾åˆ°DSLæ–‡ä»¶: demo_qa.yaml")
        logger.info(" è¯·ç¡®ä¿å½“å‰ç›®å½•ä¸‹å­˜åœ¨ ./examples/demo_qa.yaml æ–‡ä»¶")
    except Exception as e:
        logger.error(f" DSLæ‰§è¡Œå‡ºé”™: {str(e)}")
        logger.error(f"ğŸ“ é”™è¯¯ç±»å‹: {type(e).__name__}")

    logger.info("" + "="*60)
    logger.info("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    logger.info("ğŸ“– æ ¸å¿ƒç‰¹æ€§å±•ç¤º:")
    logger.info(" è‡ªå®šä¹‰æ¨¡å‹é…ç½®ç®¡ç†")
    logger.info(" æœ¬åœ°DSLæ–‡ä»¶è¯»å–æ‰§è¡Œ")
    logger.info(" å¤šæ¨¡å‹å¹¶è¡Œ/ä¸²è¡Œæ‰§è¡Œ")
    logger.info(" å¤æ‚ä¾èµ–å…³ç³»å¤„ç†")
    logger.info(" è¯¦ç»†æ‰§è¡Œæ­¥éª¤è¿½è¸ª")
    logger.info(" å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶")
    logger.info(" æç¤º: æŸ¥çœ‹ä¸Šé¢çš„è¯¦ç»†æ—¥å¿—äº†è§£æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œæƒ…å†µ")

async def load_models_from_ollama(ollama_host):
    """ä»OllamaæœåŠ¡å™¨åŠ è½½æ¨¡å‹é…ç½®"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{ollama_host}/v1/models") as resp:
                if resp.status != 200:
                    logger.error(f" è¿æ¥Ollamaå¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status}")
                    return {}
                    
                resp_data = await resp.json()
                model_items = resp_data.get("data", [])
                
        logger.info(f" æˆåŠŸè·å– {len(model_items)} ä¸ªå¯ç”¨æ¨¡å‹")
        
        ollama_model_config = {
            'platform': 'ollama', 
            'api_url': f'{ollama_host}/api/chat',
            'auth_header': None,
            'message_format': 'ollama',
            'max_tokens': 2048,  # é€‚åˆ1Bæ¨¡å‹çš„tokené™åˆ¶
            'supports': ['temperature', 'top_k', 'top_p']
        }
        
        custom_models = {}
        for model_item in model_items:
            model_name = model_item["id"]
            custom_models[model_name] = ollama_model_config
        return custom_models
        
    except Exception as e:
        logger.error(f" åŠ è½½Ollamaæ¨¡å‹é…ç½®å¤±è´¥: {str(e)}")
        return {}

if __name__ == '__main__':
    asyncio.run(demo_basic_usage())
